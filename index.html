<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-first-article" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/18/first-article/" class="article-date">
  <time class="dt-published" datetime="2023-11-18T07:15:56.000Z" itemprop="datePublished">2023-11-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/11/18/first-article/">first article</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/11/18/first-article/" data-id="clp3r0ra40000lekng0tn6uj6" data-title="first article" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/11/18/hello-world/" class="article-date">
  <time class="dt-published" datetime="2023-11-18T05:38:15.920Z" itemprop="datePublished">2023-11-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/11/18/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/11/18/hello-world/" data-id="clp3r0rab0002lekn9nzd55xy" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-python神经网络读书笔记" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2018/10/08/python%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" class="article-date">
  <time class="dt-published" datetime="2018-10-08T04:38:38.000Z" itemprop="datePublished">2018-10-08</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p><img src="https://images-cn.ssl-images-amazon.com/images/I/4120NkDh3oL._SY346_.jpg"></p>
<p>这本书从神经网络的来源到算法模型再到实际代码均有比较详细的介绍，最终成型的算法也十分简单有效，是本不错的入门书籍，这里简单记录下主要内容。其中有自己的理解也有书中的引用，个人也只是初学者，难免有认识错误或者不全面的地方。</p>
<h4 id="1-神经网络如何工作"><a href="#1-神经网络如何工作" class="headerlink" title="1.神经网络如何工作"></a>1.神经网络如何工作</h4><p>“神经网络”的名称来自于动物神经系统的基本单元神经元，我们在生物课上都学过，动物的神经细胞由细胞体、树突、轴突等组成，神经信号经由树突传给轴突，再经由轴突传给其他神经细胞，而神经网络模拟的就是这神经细胞之间信息传递的过程。即：输入信号-&gt;神经元-&gt;输出信号的过程，通过训练达到我们想要的模型。</p>
<p><img src="https://i.imgur.com/b4ZeI98.png"></p>
<p>&uarr;神经元结构(来自 维基百科)</p>
<p>神经网络的工作流程，借用网络上比较流行的段子来说明：</p>
<blockquote>
<p>1.用户：帮我计算一下1+1&#x3D;？</p>
<p>2.神经网络：40</p>
<p>3.用户：你TM在逗我，明明等于2！</p>
<p>4.用户：再问你一遍，1+1&#x3D;？</p>
<p>5.神经网络：2</p>
</blockquote>
<p>虽然是一个段子但是很简单明确的反映了神经网络的工作原理，以上步骤对应神经网络的工作步骤就是：</p>
<blockquote>
<p>1:训练集输入</p>
<p>2:当前模型的输出结果</p>
<p>3:训练集的真实结果，反馈给模型进行学习</p>
<p>&uarr;以上3步重复进行就是使用训练集对模型进行训练的过程，模型会在此过程中不断根据真实结果逆向传播误差，然后修正每个节点的参数</p>
<p>4:测试集输入</p>
<p>5:测试集输出</p>
</blockquote>
<p>可以看出，训练数据对于神经网络有效与否至关重要，就像我们学习，如果传授给我们的答案是错误的，那无论怎么学习结果只会一直错下去。</p>
<p>而神经网络学习的过程其实就是根据输出结果与真实结果的差，反向传播误差用来更新节点</p>
<h4 id="2-神经网络的应用"><a href="#2-神经网络的应用" class="headerlink" title="2.神经网络的应用"></a>2.神经网络的应用</h4><p>计算机所擅长的是进行大量重复性的工作，比如进行大量的数值运算，但是对于一些需要主观判断的行为却无能为力，比如图像识别、语义分析等等，简单来说就是计算机不会“思考”，只能以给定的逻辑去执行任务，而人却恰恰相反，擅长进行“思考”，但面对重复性工作时效率和准确率却远远不如计算机。</p>
<p>例如人可以识别出下面图片中左边是猫，右边是狗，但是对于计算机如果输入一张图片让它判断这是什么动物却很困难。</p>
<figure class="half">
    <img src="http://www.wallpaper-box.com/cat/images/cat14.jpg" width = "300" height = "200">
    <img src="http://images.ccoo.cn/bbs/20111224/2011122416564927.jpg" width = "300" height = "200">
</figure>

<p>如果要让计算机能够判断出图片中的是什么动物，就需要把图片中的信息转化成一定的特征信息，通过计算得到输出结果，将输出与事先训练得到的结果集进行比对，然后根据结果与集的相似程度将其归类。例如上面的例子，将图片1输入，得到结果为5，图片2输入结果为17，而根据先前的训练结果，数值为1-10之间的表示猫的分类，11-20的表示狗的分类，通过结果落入的区间即可判断输入图片的分类。神经网络的核心其实就是一个分类器，通过这个分类器可以进行诸如图片识别、文本识别、基于历史的预测等复杂的工作。</p>
<h4 id="3-神经网络如何进行学习"><a href="#3-神经网络如何进行学习" class="headerlink" title="3.神经网络如何进行学习"></a>3.神经网络如何进行学习</h4><p>下图为一个简单的三层神经网络结构</p>
<p><img src="https://i.imgur.com/HzEVVzY.png" alt="Imgur"></p>
<p>​                                    &uarr;来自《python神经网络编程》书内示意图</p>
<ul>
<li>输入值$X_{input} &#x3D; \begin{vmatrix}0.9\0.1\0.8\end{vmatrix}$，$w_{i,j}$表示节点i-&gt;j的权重，实际上的权重为一个i*j的矩阵，上图中输入层-&gt;隐藏层的权重矩阵表示为：</li>
</ul>
<p>​       $$W_{input_hidden} &#x3D; \begin{vmatrix}  w_{1,1}&amp;w_{2,1}&amp; w_{3,1}&amp;\  w_{1,2}&amp; w_{2,2}&amp; w_{3,2}&amp;\  w_{1,3}&amp; w_{2,3}&amp; w_{3,3} \end{vmatrix}$$</p>
<ul>
<li><p>输入层1-&gt;隐藏层2的计算过程即为X分别与每个权重相乘的到的结果，矩阵表示为：</p>
<p>$$X_{hidden}&#x3D;W_{input_hidden} \cdot X_{input} &#x3D; \begin{vmatrix}  w_{1,1}&amp;w_{2,1}&amp; w_{3,1}&amp;\  w_{1,2}&amp; w_{2,2}&amp; w_{3,2}&amp;\  w_{1,3}&amp; w_{2,3}&amp; w_{3,3} \end{vmatrix} \cdot \begin{vmatrix}0.9\0.1\0.8\end{vmatrix} ​$$</p>
<p>隐藏层2-&gt;输出层3的过程也类似，即$ X_{output} &#x3D; W_{hidden_output} \cdot X_{hidden} $，在实际运算过程中，由于输入值存在较大偏差，以至于有些输入值会超过一定的阈值导致对结果影响较大，所以为了让结果范围可控且尽量减小极端值造成的影响，需要设置一个激活函数S，有时也成逻辑函数，在此案例中$S&#x3D;\frac{1}{1+e^{-x}}$，函数图像：</p>
</li>
</ul>
<p><img src="https://i.imgur.com/yzlHEKN.jpg"></p>
<p>​	此函数的目的是使输入值更加平滑且范围可控，因此，以上公式更新为：</p>
<p>​	$X_{hidden}&#x3D;S(W_{input_hidden} \cdot X_{input}) $</p>
<p>​	加入S函数之后，流程如下图所示：</p>
<p><img src="https://i.imgur.com/fauu2NO.png"></p>
<p>​                                              &uarr;来自《python神经网络编程》书内示意图</p>
<ul>
<li><p>神经网络的训练过程，其实就是不断调整W节点权重的过程，调整的依据，就是X的输出值与实际结果T的差值E，如果E&gt;0说明输出值高于预期，需要减小权重，反之则需要增大权重。由于输出结果是经过n层计算得到的，因此在分配误差时也需要考虑节点对误差的贡献，而贡献值与节点权重成正比，隐藏节点的误差值则又输出节点的误差值反向求得</p>
<p>$ e_{hidden_i}&#x3D;e_{output_1}* \frac{w_{1,1}}{w_{1,1}+w_{2,1}}+e_{output_2}* \frac{w_{1,2}}{w_{1,2}+2_{2,2}}   $</p>
<p>如下图所示，隐藏层节点1的误差$e_{hidden_1}&#x3D;0.8<em>\frac{2}{2+3}+0.5</em>\frac{1}{1+4}&#x3D;0.42$</p>
</li>
</ul>
<p>​    <img src="https://i.imgur.com/7pZuS5l.png"></p>
<p>​            &uarr;来自《python神经网络编程》书内示意图</p>
<ul>
<li><p>较大权重就味着携带较多的输出误差给隐藏层，分母是为了将总误差归一化设置的，而我们仅仅需要表示权重与误差量的关系，实际上可以将分母忽略，即忽略后反馈误差的大小，即可将公式简化为：</p>
<p>$ e_{hidden_i}&#x3D;e_{output_1}* w_{1,1}+e_{output_2}* w_{1,2}   $</p>
<p>用矩阵表示为：</p>
<p>$e_{hidden}&#x3D;\begin{vmatrix} w_{1,1}&amp;w_{1,2}\ w_{2,1}&amp;w_{2,2}\end{vmatrix}\cdot \begin{vmatrix} e_1\e_2 \end{vmatrix} $</p>
<p>可以观察到，其中的权重矩阵w实际上为之前计算输出值时权重矩阵的转置，由此可以得：</p>
<p>$ e_{hidden}&#x3D; W^T_{hidden_output}\cdot e_{output}$</p>
<p>在数学中用函数的斜率来表示函数某一点的变化率，这里可以用同样的方法表示神经网络中w与e之间的函数的变化关系，但是神经网络本身并不是一个误差函数，而是一个极其复杂的多维度函数，会有很多的参数影响最终的输出结果，为了让我们能更直观的达到目标，需要使用<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95">梯度下降法</a>。我们的目标并不是得到函数的表达式，而是得到函数的最低点，而梯度下降，就是随机在函数中设置一个起始点，然后通过不断的向低点方向移动来得到最低点的位置。是否达到最低点，只需要知道当前点的斜率是否为零即可。但是根据初始值的不同，我们找到的最低点可能也会不同，同一函数会有多个斜率为1的点，但斜率为1并不一定是最低点，也可能只是局部的最低点，所以需要多次实验才能达到目标。</p>
</li>
</ul>
<p><img src="http://5b0988e595225.cdn.sohucs.com/images/20171118/20b7ebdd3dcc4147b1d42b7de01cc748.jpeg"></p>
<p>​	在此案例中我们需要调整权重以达到误差的最小化，所以变化关系用斜率表示为 $ \frac{\partial E}{\partial w_{ij}} $，如下图所示。</p>
<p><img src="https://i.imgur.com/DJuXRfZ.png"></p>
<p>​                                                       &uarr;来自《python神经网络编程》书内示意图</p>
<ul>
<li><p>误差值e&#x3D;目标值t-输出值o，但这样就会存在正负误差，如果相互抵消使得结果为0或者接近0也不是我们想要				的结果，所以一种方法是取误差的绝对值，即$e&#x3D;|t-o|$，这种方法可行，但是在临近最低点时斜率并不会变得更小，可能会造成在最低点左右来回滚动的情况，为了防止这种情况可以使用平方，即：$e&#x3D;(t-o)^2$，这样可以保证误差为正且在接近零点是保持连续，方便进行计算。</p>
</li>
<li><p>带入误差关系式可得：</p>
<p>$ \frac{\partial E}{\partial w_{ij}} &#x3D; \frac{\partial}{\partial w_{i,j}}\sum_n(t_j-o_j)^2 $</p>
<p>同时根据链式法则：</p>
<p>$\frac{\partial E}{\partial w_{ij}} &#x3D; \frac{\partial E}{\partial o_j}\cdot\frac{\partial o_j}{\partial w_{i,j}} $</p>
<p>由于t是常数，所以：</p>
<p>$ \frac{\partial E}{\partial w_{ij}}&#x3D;-2(t_j-o_j)\cdot\frac{\partial o_j}{\partial w_{i,j}} $</p>
<p>$o_j $是节点j的输出，带入S函数可得：</p>
<p>$\frac{\partial E}{\partial w_{ij}} &#x3D;-2(t_j-o_j)\cdot\frac{\partial}{\partial w_{i,j}}S(\sum_iw_{i,j}\cdot o_i)$</p>
<p>这里我们需要得到S函数的微分结果：</p>
<p>$S’&#x3D;\frac{\partial}{\partial x}(\frac{1}{1+e^{-x}})&#x3D;(-(1+e^{-x})^{-2}*(1+e^{-x})’)&#x3D;\frac{e^{-x}}{(1+e^{-x	})^2}&#x3D;\frac{1}{1+e^{-x}}-(\frac{1}{1+e^{-x}})^2&#x3D;S(1-S)$</p>
<p>所以：</p>
<p>$\frac{\partial E}{\partial w_{ij}} &#x3D;-2(t_j-o_j)\cdot S(\sum_iw_{i,j}\cdot o_i)(1-S(\sum_i w_{i,j}\cdot o_i))\cdot \frac{\partial}{\partial w_{i,j}}(\sum_i w_{i,j}\cdot o_i)$</p>
</li>
</ul>
<p>​         $$&#x3D;-2(t_j-o_j)·S(\sum_iw_{ij}·o_i)(1-S(\sum_iw_{ij}·o_i))·o_i$$ </p>
<p>​	由于斜率只考虑方向不考虑大小，所以忽略参数2：</p>
<p>​	$\frac{\partial E}{\partial w_{ij}}&#x3D;-(e_j)·sigmoid(\sum_iw_{ij}·o_i)(1-sigmoid(\sum_iw_{ij}·o_i))·o_i$</p>
<p>​	权重的变化与斜率符号相反，且为了避免在最小值附近摆动，引入新的学习因子$\alpha$，权重的更新方式可以用下式来表示：</p>
<p>​	$new\space w_{i,j}&#x3D;old\space w_{i,j}-\alpha\cdot\frac{\partial E}{\partial w_{i,j}}$</p>
<p>​	用矩阵来表示权重w的变化，省略学习因子$\alpha$，o表示前一层的输出值：</p>
<p>​	$$\begin{vmatrix} \Delta w_{1,1}&amp;\Delta w_{2,1}&amp;\Delta w_{3,1}&amp;\cdots\ \Delta w_{1,2}&amp;\Delta w_{2,2}&amp;\Delta w_{3,2}&amp;\cdots\ \Delta w_{1,3}&amp;\Delta w_{2,3}&amp;\Delta w_{3,3}&amp;\cdots\ \vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp; \end{vmatrix} $$  &#x3D; $$\begin{vmatrix} E_1<em>S_1(1-S_1)\E_1</em>S_2(1-S_2)\E_3*S_3(1-S_3)\ \vdots \end{vmatrix} \cdot \begin{vmatrix}o_1&amp;o_2&amp;o_3&amp;\cdots\end{vmatrix}$$</p>
<p>​	化简后的矩阵表达式：</p>
<p>​	$\Delta W_{i,j}&#x3D;\alpha\cdot E_j\cdot O_j(1-O_j)\cdot O_i^T$</p>
<h4 id="4-python代码实现"><a href="#4-python代码实现" class="headerlink" title="4.python代码实现"></a>4.python代码实现</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> expit</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ANN</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, inputnodes, hiddennodes, outputnodes, learningrate</span>):</span><br><span class="line">        self.inodes = inputnodes</span><br><span class="line">        self.hnodes = hiddennodes</span><br><span class="line">        self.onodes = outputnodes</span><br><span class="line">        self.lr = learningrate</span><br><span class="line">        <span class="comment">#设置初始权重，采用正态分布随机获得</span></span><br><span class="line">        self.wih = np.random.normal(<span class="number">0</span>, <span class="built_in">pow</span>(self.hnodes,-<span class="number">0.5</span>), (self.hnodes,self.inodes))</span><br><span class="line">        self.who = np.random.normal(<span class="number">0</span>, <span class="built_in">pow</span>(self.onodes,-<span class="number">0.5</span>), (self.onodes,self.hnodes))</span><br><span class="line">        self.act_function = <span class="keyword">lambda</span> x: expit(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#训练函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">self,inputs,targets</span>):</span><br><span class="line">        inputs = np.array(inputs,ndmin=<span class="number">2</span>).T </span><br><span class="line">        targets = np.array(targets,ndmin=<span class="number">2</span>).T  <span class="comment">#目标值</span></span><br><span class="line">        </span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs)</span><br><span class="line">        hidden_outputs = self.act_function(hidden_inputs)</span><br><span class="line">        </span><br><span class="line">        final_inputs = np.dot(self.who,hidden_outputs)</span><br><span class="line">        final_outputs = self.act_function(final_inputs)</span><br><span class="line">        </span><br><span class="line">        output_errors = targets -final_outputs</span><br><span class="line">        hidden_errors = np.dot(self.who.T, output_errors)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#反向传递误差</span></span><br><span class="line">        self.who += self.lr * np.dot((output_errors * final_outputs * (<span class="number">1</span>-final_outputs)), np.transpose(hidden_outputs))</span><br><span class="line">        self.wih += self.lr * np.dot((hidden_errors * hidden_outputs * (<span class="number">1</span>-hidden_outputs)), np.transpose(inputs))</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#查询函数</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">query</span>(<span class="params">self, inputs</span>):</span><br><span class="line">        inputs = np.array(inputs,ndmin=<span class="number">2</span>).T </span><br><span class="line">        hidden_inputs = np.dot(self.wih, inputs)</span><br><span class="line">        hidden_outputs = self.act_function(hidden_inputs)</span><br><span class="line">        </span><br><span class="line">        final_inputs = np.dot(self.who,hidden_outputs)</span><br><span class="line">        final_outputs = self.act_function(final_inputs)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> final_outputs</span><br><span class="line"></span><br><span class="line"><span class="comment">#测试</span></span><br><span class="line">inodes = <span class="number">3</span></span><br><span class="line">hnodes = <span class="number">3</span></span><br><span class="line">onodes = <span class="number">3</span></span><br><span class="line">lr = <span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">t = ANN(inodes,hnodes,onodes,lr)</span><br><span class="line">t.train([<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">0.2</span>,<span class="number">0.33</span>,<span class="number">15</span>])</span><br><span class="line">t.query([<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h4 id="5-手写数字识别"><a href="#5-手写数字识别" class="headerlink" title="5.手写数字识别"></a>5.手写数字识别</h4><p>训练集 <a target="_blank" rel="noopener" href="http://www.pjreddie.com/media/files/mnist_train.csv">http://www.pjreddie.com/media/files/mnist_train.csv</a> </p>
<p>测试集 <a target="_blank" rel="noopener" href="http://www.pjreddie.com/media/files/mnist_test.csv">http://www.pjreddie.com/media/files/mnist_test.csv</a></p>
<p>此数据集由两部分组成，每行第一位为手写数字结果，后面为28*28的方形像素值，数值越大代表颜色越深<img src="https://i.imgur.com/LMpjYY2.png"></p>
<p>如果将数据可视化的话会得到如下的图，可以明显看出所写数字为8:</p>
<p><img src="https://i.imgur.com/dsA83El.jpg"></p>
<p>我们的目标就是让神经网络根据数据识别出所写数字。</p>
<p>训练及测试代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;mnist_train.csv&#x27;</span>,<span class="string">&quot;r&quot;</span>)</span><br><span class="line">train_data = f.readlines()</span><br><span class="line">f.close()</span><br><span class="line"></span><br><span class="line">inodes = <span class="number">784</span></span><br><span class="line">hnodes = <span class="number">100</span></span><br><span class="line">onodes = <span class="number">10</span></span><br><span class="line">lr = <span class="number">0.3</span></span><br><span class="line">nt = ANN(inodes,hnodes,onodes,lr)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> train_data:</span><br><span class="line">    one = line.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line"></span><br><span class="line">    inputs = np.asfarray(one[<span class="number">1</span>:])/<span class="number">255</span>*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    targets = np.zeros(onodes) + <span class="number">0.01</span></span><br><span class="line">    targets[<span class="built_in">int</span>(one[<span class="number">0</span>])] = <span class="number">0.99</span></span><br><span class="line">    </span><br><span class="line">    nt.train(inputs,targets)</span><br><span class="line"></span><br><span class="line">f = <span class="built_in">open</span>(<span class="string">&#x27;mnist_test.csv&#x27;</span>,<span class="string">&quot;r&quot;</span>)</span><br><span class="line">test_data = f.readlines()</span><br><span class="line">f.close()</span><br><span class="line">result = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> test <span class="keyword">in</span> test_data:</span><br><span class="line">    one_test = test.split(<span class="string">&quot;,&quot;</span>)</span><br><span class="line">    inputs = np.asfarray(one_test[<span class="number">1</span>:])/<span class="number">255</span>*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#print(one_test[0],str(np.argmax(nt.query(inputs))))</span></span><br><span class="line">    <span class="keyword">if</span> np.argmax(nt.query(inputs)) == <span class="built_in">int</span>(one_test[<span class="number">0</span>]):</span><br><span class="line">        result.append(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        result.append(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;finished 正确率 %.1f%%&quot;</span> %(<span class="built_in">sum</span>(result)/<span class="built_in">len</span>(result) *<span class="number">100</span>))</span><br></pre></td></tr></table></figure>

<p>最终准确率达到94.3%，已经是一个非常不错的结果了。下一步可以通过调整学习因子$\alpha$、训练次数、节点个数来进一步提升准确率，但准确率的提升有一定限度，到达一定限度之后再提升训练次数反而会使准确率下降，学习率也是如此，这些参数需要通过不断测试来得到最优。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2018/10/08/python%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" data-id="clp3r0raa0001lekn5l4p3gqz" data-title="" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/10/">October 2018</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/11/18/first-article/">first article</a>
          </li>
        
          <li>
            <a href="/2023/11/18/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2018/10/08/python%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>